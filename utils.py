import av
from ultralytics import YOLO
import streamlit as st
import cv2
from PIL import Image
import tempfile
from streamlit_webrtc import VideoProcessorBase, WebRtcMode, webrtc_streamer
import numpy as np
import os
from class_names import class_names

# --- 1. LOAD MODEL & CSS ---
@st.cache_resource
def load_model():
    # ƒê·∫£m b·∫£o b·∫°n c√≥ file yolov8n.pt trong th∆∞ m·ª•c model
    return YOLO("./model/yolov8n.pt")

def styling_css():
    # Load CSS n·∫øu c√≥
    if os.path.exists('./assets/css/general-style.css'):
        with open('./assets/css/general-style.css') as f:
            st.markdown(f'<style>{f.read()}</style>', unsafe_allow_html=True)

# --- 2. H√ÄM HI·ªÇN TH·ªä K·∫æT QU·∫¢ (D√πng Streamlit Native - Kh√¥ng l·ªói HTML) ---
def display_results(results, container_placeholder):
    # X√≥a n·ªôi dung c≈© trong khung ch·ª©a
    container = container_placeholder.container()
    
    with container:
        st.divider()
        st.subheader("ü•ó K·∫øt qu·∫£ ph√¢n t√≠ch")
        
        total_calories = 0
        total_fat = 0
        found_any = False
        
        # Duy·ªát qua c√°c k·∫øt qu·∫£
        for r in results:
            for box in r.boxes:
                class_id = int(box.cls[0].item())
                
                # B·ªè qua n·∫øu ID l·∫° kh√¥ng c√≥ trong danh s√°ch
                if class_id >= len(class_names): continue
                
                info = class_names[class_id]
                name = info["name"]
                conf = int(box.conf[0].item() * 100)
                nutri = info["nutrition"]
                serving = info["serving_type"]
                
                found_any = True
                total_calories += nutri.get('Calories', 0)
                total_fat += nutri.get('Fat', 0)
                
                # --- S·ª¨A L·ªñI ·ªû ƒê√ÇY: D√πng st.expander v√† st.metric thay v√¨ HTML ---
                with st.expander(f"üîπ {name} (ƒê·ªô tin c·∫≠y: {conf}%)", expanded=True):
                    st.caption(f"üìè Kh·∫©u ph·∫ßn: {serving}")
                    
                    # Chia th√†nh 4 c·ªôt ƒë·ªÉ hi·ªÉn th·ªã ch·ªâ s·ªë ƒë·∫πp m·∫Øt
                    c1, c2, c3, c4 = st.columns(4)
                    c1.metric("üî• Calo", f"{nutri.get('Calories', 0)}")
                    c2.metric("ü•© Ch·∫•t b√©o", f"{nutri.get('Fat', 0)}g")
                    c3.metric("üç¨ ƒê∆∞·ªùng", f"{nutri.get('Sugar', 0)}g")
                    c4.metric("üßÇ Mu·ªëi", f"{nutri.get('Salt', 0)}g")

        # Hi·ªÉn th·ªã t·ªïng k·∫øt
        if found_any:
            st.success(f"üìä **T·ªîNG K·∫æT:** B·ªØa ƒÉn n√†y kho·∫£ng **{total_calories} kcal** v√† **{total_fat}g ch·∫•t b√©o**.")
        else:
            st.warning("‚ö†Ô∏è Kh√¥ng nh·∫≠n di·ªán ƒë∆∞·ª£c m√≥n ƒÉn n√†o trong danh s√°ch d·ªØ li·ªáu.")

# --- 3. CH·ª®C NƒÇNG: ·∫¢NH ---
def detect_image(conf, uploaded_file, model):
    image = Image.open(uploaded_file)
    col1, col2 = st.columns(2)
    
    with col1:
        st.image(image, caption="·∫¢nh g·ªëc", use_container_width=True)
    
    if st.button("üîç Ph√¢n t√≠ch ngay"):
        with st.spinner("ƒêang x·ª≠ l√Ω AI..."):
            results = model.predict(image, conf=conf)
            res_plotted = results[0].plot()
            
            # Chuy·ªÉn m√†u BGR -> RGB ƒë·ªÉ hi·ªÉn th·ªã ƒë√∫ng
            res_image = Image.fromarray(res_plotted[..., ::-1])
            
            with col2:
                st.image(res_image, caption="K·∫øt qu·∫£ nh·∫≠n di·ªán", use_container_width=True)
            
            # G·ªçi h√†m hi·ªÉn th·ªã k·∫øt qu·∫£ m·ªõi
            display_results(results, st.empty())

# --- 4. CH·ª®C NƒÇNG: VIDEO ---
def detect_video(conf, uploaded_file, model):
    tfile = tempfile.NamedTemporaryFile(delete=False) 
    tfile.write(uploaded_file.read())
    
    cap = cv2.VideoCapture(tfile.name)
    st_frame = st.empty()
    stop_btn = st.button("‚èπÔ∏è D·ª´ng video")
    
    while cap.isOpened() and not stop_btn:
        ret, frame = cap.read()
        if not ret: break
        
        results = model.predict(frame, conf=conf)
        res_plotted = results[0].plot()
        
        # Hi·ªÉn th·ªã video realtime
        st_frame.image(res_plotted, channels="BGR", use_container_width=True)
    
    cap.release()

# --- 5. CH·ª®C NƒÇNG: WEBCAM ---
class VideoTransformer(VideoProcessorBase):
    def __init__(self, conf, model):
        self.conf = conf
        self.model = model

    def recv(self, frame: av.VideoFrame) -> av.VideoFrame:
        img = frame.to_ndarray(format="bgr24")
        results = self.model.predict(img, conf=self.conf)
        img_plotted = results[0].plot()
        return av.VideoFrame.from_ndarray(img_plotted, format="bgr24")

def detect_webcam(conf, model):
    webrtc_streamer(
        key="food-detection",
        mode=WebRtcMode.SENDRECV,
        video_transformer_factory=lambda: VideoTransformer(conf, model),
        media_stream_constraints={"video": True, "audio": False},
        async_processing=True,
    )

# --- 6. CH·ª®C NƒÇNG: IP CAMERA ---
def detect_camera(conf, model, address):
    cap = cv2.VideoCapture(address)
    st_frame = st.empty()
    stop_btn = st.button("Ng·∫Øt k·∫øt n·ªëi")
    
    while cap.isOpened() and not stop_btn:
        ret, frame = cap.read()
        if not ret:
            st.error("Kh√¥ng th·ªÉ k·∫øt n·ªëi t·ªõi Camera IP.")
            break
            
        results = model.predict(frame, conf=conf)
        res_plotted = results[0].plot()
        st_frame.image(res_plotted, channels="BGR", use_container_width=True)
    
    cap.release()